digraph {
	graph [size="187.95,187.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3039447486112 [label="
 (3, 3, 473, 473)" fillcolor=darkolivegreen1]
	3039448394000 [label=UpsampleBilinear2DBackward1]
	3039448394096 -> 3039448394000
	3039448394096 [label=AddBackward0]
	3039448393904 -> 3039448394096
	3039448393904 [label=CudnnConvolutionBackward0]
	3039448394192 -> 3039448393904
	3039448394192 [label=MulBackward0]
	3039448394336 -> 3039448394192
	3039448394336 [label=ReluBackward0]
	3039448394432 -> 3039448394336
	3039448394432 [label=CudnnBatchNormBackward0]
	3039448394528 -> 3039448394432
	3039448394528 [label=CudnnConvolutionBackward0]
	3039448394720 -> 3039448394528
	3039448394720 [label=CatBackward0]
	3039448394864 -> 3039448394720
	3039448394864 [label=CudnnBatchNormBackward0]
	3039448395152 -> 3039448394864
	3039448395152 [label=CudnnConvolutionBackward0]
	3039448395344 -> 3039448395152
	3039448395344 [label=HardtanhBackward0]
	3039448395488 -> 3039448395344
	3039448395488 [label=CudnnBatchNormBackward0]
	3039448395584 -> 3039448395488
	3039448395584 [label=ConvDepthwise2DBackward0]
	3039448395728 -> 3039448395584
	3039448395728 [label=HardtanhBackward0]
	3039448572112 -> 3039448395728
	3039448572112 [label=CudnnBatchNormBackward0]
	3039448572208 -> 3039448572112
	3039448572208 [label=CudnnConvolutionBackward0]
	3039448572400 -> 3039448572208
	3039448572400 [label=AddBackward0]
	3039448572544 -> 3039448572400
	3039448572544 [label=AddBackward0]
	3039448572688 -> 3039448572544
	3039448572688 [label=CudnnBatchNormBackward0]
	3039448572832 -> 3039448572688
	3039448572832 [label=CudnnConvolutionBackward0]
	3039448573024 -> 3039448572832
	3039448573024 [label=HardtanhBackward0]
	3039448573168 -> 3039448573024
	3039448573168 [label=CudnnBatchNormBackward0]
	3039448573264 -> 3039448573168
	3039448573264 [label=ConvDepthwise2DBackward0]
	3039448573456 -> 3039448573264
	3039448573456 [label=HardtanhBackward0]
	3039448573600 -> 3039448573456
	3039448573600 [label=CudnnBatchNormBackward0]
	3039448573696 -> 3039448573600
	3039448573696 [label=CudnnConvolutionBackward0]
	3039448573888 -> 3039448573696
	3039448573888 [label=AddBackward0]
	3039448574032 -> 3039448573888
	3039448574032 [label=AddBackward0]
	3039448574176 -> 3039448574032
	3039448574176 [label=CudnnBatchNormBackward0]
	3039448574320 -> 3039448574176
	3039448574320 [label=CudnnConvolutionBackward0]
	3039448574512 -> 3039448574320
	3039448574512 [label=HardtanhBackward0]
	3039448574656 -> 3039448574512
	3039448574656 [label=CudnnBatchNormBackward0]
	3039448574752 -> 3039448574656
	3039448574752 [label=ConvDepthwise2DBackward0]
	3039448574944 -> 3039448574752
	3039448574944 [label=HardtanhBackward0]
	3039448575088 -> 3039448574944
	3039448575088 [label=CudnnBatchNormBackward0]
	3039448575184 -> 3039448575088
	3039448575184 [label=CudnnConvolutionBackward0]
	3039448575376 -> 3039448575184
	3039448575376 [label=AddBackward0]
	3039448575520 -> 3039448575376
	3039448575520 [label=AddBackward0]
	3039448575664 -> 3039448575520
	3039448575664 [label=AddBackward0]
	3039448575808 -> 3039448575664
	3039448575808 [label=CudnnBatchNormBackward0]
	3039448575952 -> 3039448575808
	3039448575952 [label=CudnnConvolutionBackward0]
	3039448584400 -> 3039448575952
	3039448584400 [label=HardtanhBackward0]
	3039448584544 -> 3039448584400
	3039448584544 [label=CudnnBatchNormBackward0]
	3039448584640 -> 3039448584544
	3039448584640 [label=ConvDepthwise2DBackward0]
	3039448584832 -> 3039448584640
	3039448584832 [label=HardtanhBackward0]
	3039448584976 -> 3039448584832
	3039448584976 [label=CudnnBatchNormBackward0]
	3039448585072 -> 3039448584976
	3039448585072 [label=CudnnConvolutionBackward0]
	3039448585264 -> 3039448585072
	3039448585264 [label=AddBackward0]
	3039448585408 -> 3039448585264
	3039448585408 [label=AddBackward0]
	3039448585552 -> 3039448585408
	3039448585552 [label=CudnnBatchNormBackward0]
	3039448585696 -> 3039448585552
	3039448585696 [label=CudnnConvolutionBackward0]
	3039448585888 -> 3039448585696
	3039448585888 [label=HardtanhBackward0]
	3039448586032 -> 3039448585888
	3039448586032 [label=CudnnBatchNormBackward0]
	3039448586128 -> 3039448586032
	3039448586128 [label=ConvDepthwise2DBackward0]
	3039448586320 -> 3039448586128
	3039448586320 [label=HardtanhBackward0]
	3039448586464 -> 3039448586320
	3039448586464 [label=CudnnBatchNormBackward0]
	3039448586512 -> 3039448586464
	3039448586512 [label=CudnnConvolutionBackward0]
	3039448586800 -> 3039448586512
	3039448586800 [label=AddBackward0]
	3039448586944 -> 3039448586800
	3039448586944 [label=CudnnBatchNormBackward0]
	3039448587088 -> 3039448586944
	3039448587088 [label=CudnnConvolutionBackward0]
	3039448587280 -> 3039448587088
	3039448587280 [label=HardtanhBackward0]
	3039448587424 -> 3039448587280
	3039448587424 [label=CudnnBatchNormBackward0]
	3039448587472 -> 3039448587424
	3039448587472 [label=ConvDepthwise2DBackward0]
	3039448587760 -> 3039448587472
	3039448587760 [label=HardtanhBackward0]
	3039448587904 -> 3039448587760
	3039448587904 [label=CudnnBatchNormBackward0]
	3039448587952 -> 3039448587904
	3039448587952 [label=CudnnConvolutionBackward0]
	3039448588240 -> 3039448587952
	3039448588240 [label=CudnnBatchNormBackward0]
	3039448596640 -> 3039448588240
	3039448596640 [label=CudnnConvolutionBackward0]
	3039448596832 -> 3039448596640
	3039448596832 [label=HardtanhBackward0]
	3039448596976 -> 3039448596832
	3039448596976 [label=CudnnBatchNormBackward0]
	3039448597024 -> 3039448596976
	3039448597024 [label=ConvDepthwise2DBackward0]
	3039448597312 -> 3039448597024
	3039448597312 [label=HardtanhBackward0]
	3039448597456 -> 3039448597312
	3039448597456 [label=CudnnBatchNormBackward0]
	3039448597504 -> 3039448597456
	3039448597504 [label=CudnnConvolutionBackward0]
	3039448597792 -> 3039448597504
	3039447485712 [label="backbone.features.0.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	3039447485712 -> 3039448597792
	3039448597792 [label=AccumulateGrad]
	3039448597360 -> 3039448597456
	3039447485792 [label="backbone.features.0.1.weight
 (32)" fillcolor=lightblue]
	3039447485792 -> 3039448597360
	3039448597360 [label=AccumulateGrad]
	3039448597600 -> 3039448597456
	3039447485872 [label="backbone.features.0.1.bias
 (32)" fillcolor=lightblue]
	3039447485872 -> 3039448597600
	3039448597600 [label=AccumulateGrad]
	3039448597264 -> 3039448597024
	3039447486272 [label="backbone.features.1.conv.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	3039447486272 -> 3039448597264
	3039448597264 [label=AccumulateGrad]
	3039448596880 -> 3039448596976
	3039447486352 [label="backbone.features.1.conv.1.weight
 (32)" fillcolor=lightblue]
	3039447486352 -> 3039448596880
	3039448596880 [label=AccumulateGrad]
	3039448597120 -> 3039448596976
	3039447515200 [label="backbone.features.1.conv.1.bias
 (32)" fillcolor=lightblue]
	3039447515200 -> 3039448597120
	3039448597120 [label=AccumulateGrad]
	3039448596784 -> 3039448596640
	3039447515600 [label="backbone.features.1.conv.3.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	3039447515600 -> 3039448596784
	3039448596784 [label=AccumulateGrad]
	3039448596592 -> 3039448588240
	3039447515680 [label="backbone.features.1.conv.4.weight
 (16)" fillcolor=lightblue]
	3039447515680 -> 3039448596592
	3039448596592 [label=AccumulateGrad]
	3039448596544 -> 3039448588240
	3039447515760 [label="backbone.features.1.conv.4.bias
 (16)" fillcolor=lightblue]
	3039447515760 -> 3039448596544
	3039448596544 [label=AccumulateGrad]
	3039448588192 -> 3039448587952
	3039447516160 [label="backbone.features.2.conv.0.weight
 (96, 16, 1, 1)" fillcolor=lightblue]
	3039447516160 -> 3039448588192
	3039448588192 [label=AccumulateGrad]
	3039448587808 -> 3039448587904
	3039447516240 [label="backbone.features.2.conv.1.weight
 (96)" fillcolor=lightblue]
	3039447516240 -> 3039448587808
	3039448587808 [label=AccumulateGrad]
	3039448588048 -> 3039448587904
	3039447516320 [label="backbone.features.2.conv.1.bias
 (96)" fillcolor=lightblue]
	3039447516320 -> 3039448588048
	3039448588048 [label=AccumulateGrad]
	3039448587712 -> 3039448587472
	3039447516720 [label="backbone.features.2.conv.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	3039447516720 -> 3039448587712
	3039448587712 [label=AccumulateGrad]
	3039448587328 -> 3039448587424
	3039447516800 [label="backbone.features.2.conv.4.weight
 (96)" fillcolor=lightblue]
	3039447516800 -> 3039448587328
	3039448587328 [label=AccumulateGrad]
	3039448587568 -> 3039448587424
	3039447516880 [label="backbone.features.2.conv.4.bias
 (96)" fillcolor=lightblue]
	3039447516880 -> 3039448587568
	3039448587568 [label=AccumulateGrad]
	3039448587232 -> 3039448587088
	3039447517280 [label="backbone.features.2.conv.6.weight
 (24, 96, 1, 1)" fillcolor=lightblue]
	3039447517280 -> 3039448587232
	3039448587232 [label=AccumulateGrad]
	3039448587040 -> 3039448586944
	3039447517360 [label="backbone.features.2.conv.7.weight
 (24)" fillcolor=lightblue]
	3039447517360 -> 3039448587040
	3039448587040 [label=AccumulateGrad]
	3039448586992 -> 3039448586944
	3039447517440 [label="backbone.features.2.conv.7.bias
 (24)" fillcolor=lightblue]
	3039447517440 -> 3039448586992
	3039448586992 [label=AccumulateGrad]
	3039448586896 -> 3039448586800
	3039448586896 [label=CudnnBatchNormBackward0]
	3039448587664 -> 3039448586896
	3039448587664 [label=CudnnConvolutionBackward0]
	3039448588096 -> 3039448587664
	3039448588096 [label=HardtanhBackward0]
	3039448587856 -> 3039448588096
	3039448587856 [label=CudnnBatchNormBackward0]
	3039448597168 -> 3039448587856
	3039448597168 [label=ConvDepthwise2DBackward0]
	3039448597408 -> 3039448597168
	3039448597408 [label=HardtanhBackward0]
	3039448597936 -> 3039448597408
	3039448597936 [label=CudnnBatchNormBackward0]
	3039448598128 -> 3039448597936
	3039448598128 [label=CudnnConvolutionBackward0]
	3039448586944 -> 3039448598128
	3039448598320 -> 3039448598128
	3039447517840 [label="backbone.features.3.conv.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	3039447517840 -> 3039448598320
	3039448598320 [label=AccumulateGrad]
	3039448598080 -> 3039448597936
	3039447517920 [label="backbone.features.3.conv.1.weight
 (144)" fillcolor=lightblue]
	3039447517920 -> 3039448598080
	3039448598080 [label=AccumulateGrad]
	3039448598032 -> 3039448597936
	3039447518000 [label="backbone.features.3.conv.1.bias
 (144)" fillcolor=lightblue]
	3039447518000 -> 3039448598032
	3039448598032 [label=AccumulateGrad]
	3039448597648 -> 3039448597168
	3039447518400 [label="backbone.features.3.conv.3.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	3039447518400 -> 3039448597648
	3039448597648 [label=AccumulateGrad]
	3039448596688 -> 3039448587856
	3039447518480 [label="backbone.features.3.conv.4.weight
 (144)" fillcolor=lightblue]
	3039447518480 -> 3039448596688
	3039448596688 [label=AccumulateGrad]
	3039448597216 -> 3039448587856
	3039447518560 [label="backbone.features.3.conv.4.bias
 (144)" fillcolor=lightblue]
	3039447518560 -> 3039448597216
	3039448597216 [label=AccumulateGrad]
	3039448588144 -> 3039448587664
	3039447518960 [label="backbone.features.3.conv.6.weight
 (24, 144, 1, 1)" fillcolor=lightblue]
	3039447518960 -> 3039448588144
	3039448588144 [label=AccumulateGrad]
	3039448587184 -> 3039448586896
	3039447519040 [label="backbone.features.3.conv.7.weight
 (24)" fillcolor=lightblue]
	3039447519040 -> 3039448587184
	3039448587184 [label=AccumulateGrad]
	3039448587136 -> 3039448586896
	3039447519120 [label="backbone.features.3.conv.7.bias
 (24)" fillcolor=lightblue]
	3039447519120 -> 3039448587136
	3039448587136 [label=AccumulateGrad]
	3039448586752 -> 3039448586512
	3039447736704 [label="backbone.features.4.conv.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	3039447736704 -> 3039448586752
	3039448586752 [label=AccumulateGrad]
	3039448586368 -> 3039448586464
	3039447736784 [label="backbone.features.4.conv.1.weight
 (144)" fillcolor=lightblue]
	3039447736784 -> 3039448586368
	3039448586368 [label=AccumulateGrad]
	3039448586608 -> 3039448586464
	3039447736864 [label="backbone.features.4.conv.1.bias
 (144)" fillcolor=lightblue]
	3039447736864 -> 3039448586608
	3039448586608 [label=AccumulateGrad]
	3039448586272 -> 3039448586128
	3039447737264 [label="backbone.features.4.conv.3.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	3039447737264 -> 3039448586272
	3039448586272 [label=AccumulateGrad]
	3039448586080 -> 3039448586032
	3039447737344 [label="backbone.features.4.conv.4.weight
 (144)" fillcolor=lightblue]
	3039447737344 -> 3039448586080
	3039448586080 [label=AccumulateGrad]
	3039448585936 -> 3039448586032
	3039447737424 [label="backbone.features.4.conv.4.bias
 (144)" fillcolor=lightblue]
	3039447737424 -> 3039448585936
	3039448585936 [label=AccumulateGrad]
	3039448585840 -> 3039448585696
	3039447737824 [label="backbone.features.4.conv.6.weight
 (32, 144, 1, 1)" fillcolor=lightblue]
	3039447737824 -> 3039448585840
	3039448585840 [label=AccumulateGrad]
	3039448585648 -> 3039448585552
	3039447737904 [label="backbone.features.4.conv.7.weight
 (32)" fillcolor=lightblue]
	3039447737904 -> 3039448585648
	3039448585648 [label=AccumulateGrad]
	3039448585600 -> 3039448585552
	3039447737984 [label="backbone.features.4.conv.7.bias
 (32)" fillcolor=lightblue]
	3039447737984 -> 3039448585600
	3039448585600 [label=AccumulateGrad]
	3039448585504 -> 3039448585408
	3039448585504 [label=CudnnBatchNormBackward0]
	3039448586224 -> 3039448585504
	3039448586224 [label=CudnnConvolutionBackward0]
	3039448586656 -> 3039448586224
	3039448586656 [label=HardtanhBackward0]
	3039448587616 -> 3039448586656
	3039448587616 [label=CudnnBatchNormBackward0]
	3039448586848 -> 3039448587616
	3039448586848 [label=ConvDepthwise2DBackward0]
	3039448598176 -> 3039448586848
	3039448598176 [label=HardtanhBackward0]
	3039448598368 -> 3039448598176
	3039448598368 [label=CudnnBatchNormBackward0]
	3039448598464 -> 3039448598368
	3039448598464 [label=CudnnConvolutionBackward0]
	3039448585552 -> 3039448598464
	3039448598656 -> 3039448598464
	3039447738384 [label="backbone.features.5.conv.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	3039447738384 -> 3039448598656
	3039448598656 [label=AccumulateGrad]
	3039448598224 -> 3039448598368
	3039447738464 [label="backbone.features.5.conv.1.weight
 (192)" fillcolor=lightblue]
	3039447738464 -> 3039448598224
	3039448598224 [label=AccumulateGrad]
	3039448597984 -> 3039448598368
	3039447738544 [label="backbone.features.5.conv.1.bias
 (192)" fillcolor=lightblue]
	3039447738544 -> 3039448597984
	3039448597984 [label=AccumulateGrad]
	3039448598272 -> 3039448586848
	3039447738944 [label="backbone.features.5.conv.3.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	3039447738944 -> 3039448598272
	3039448598272 [label=AccumulateGrad]
	3039448586416 -> 3039448587616
	3039447739024 [label="backbone.features.5.conv.4.weight
 (192)" fillcolor=lightblue]
	3039447739024 -> 3039448586416
	3039448586416 [label=AccumulateGrad]
	3039448597744 -> 3039448587616
	3039447739104 [label="backbone.features.5.conv.4.bias
 (192)" fillcolor=lightblue]
	3039447739104 -> 3039448597744
	3039448597744 [label=AccumulateGrad]
	3039448586704 -> 3039448586224
	3039447739504 [label="backbone.features.5.conv.6.weight
 (32, 192, 1, 1)" fillcolor=lightblue]
	3039447739504 -> 3039448586704
	3039448586704 [label=AccumulateGrad]
	3039448585792 -> 3039448585504
	3039447739584 [label="backbone.features.5.conv.7.weight
 (32)" fillcolor=lightblue]
	3039447739584 -> 3039448585792
	3039448585792 [label=AccumulateGrad]
	3039448585744 -> 3039448585504
	3039447739664 [label="backbone.features.5.conv.7.bias
 (32)" fillcolor=lightblue]
	3039447739664 -> 3039448585744
	3039448585744 [label=AccumulateGrad]
	3039448585360 -> 3039448585264
	3039448585360 [label=CudnnBatchNormBackward0]
	3039448585984 -> 3039448585360
	3039448585984 [label=CudnnConvolutionBackward0]
	3039448598608 -> 3039448585984
	3039448598608 [label=HardtanhBackward0]
	3039448598752 -> 3039448598608
	3039448598752 [label=CudnnBatchNormBackward0]
	3039448598560 -> 3039448598752
	3039448598560 [label=ConvDepthwise2DBackward0]
	3039448598944 -> 3039448598560
	3039448598944 [label=HardtanhBackward0]
	3039448599088 -> 3039448598944
	3039448599088 [label=CudnnBatchNormBackward0]
	3039448599184 -> 3039448599088
	3039448599184 [label=CudnnConvolutionBackward0]
	3039448585408 -> 3039448599184
	3039448599376 -> 3039448599184
	3039447740144 [label="backbone.features.6.conv.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	3039447740144 -> 3039448599376
	3039448599376 [label=AccumulateGrad]
	3039448599136 -> 3039448599088
	3039447740224 [label="backbone.features.6.conv.1.weight
 (192)" fillcolor=lightblue]
	3039447740224 -> 3039448599136
	3039448599136 [label=AccumulateGrad]
	3039448598992 -> 3039448599088
	3039447740304 [label="backbone.features.6.conv.1.bias
 (192)" fillcolor=lightblue]
	3039447740304 -> 3039448598992
	3039448598992 [label=AccumulateGrad]
	3039448598896 -> 3039448598560
	3039447810432 [label="backbone.features.6.conv.3.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	3039447810432 -> 3039448598896
	3039448598896 [label=AccumulateGrad]
	3039448598704 -> 3039448598752
	3039447810512 [label="backbone.features.6.conv.4.weight
 (192)" fillcolor=lightblue]
	3039447810512 -> 3039448598704
	3039448598704 [label=AccumulateGrad]
	3039448598512 -> 3039448598752
	3039447810592 [label="backbone.features.6.conv.4.bias
 (192)" fillcolor=lightblue]
	3039447810592 -> 3039448598512
	3039448598512 [label=AccumulateGrad]
	3039448596928 -> 3039448585984
	3039447810992 [label="backbone.features.6.conv.6.weight
 (32, 192, 1, 1)" fillcolor=lightblue]
	3039447810992 -> 3039448596928
	3039448596928 [label=AccumulateGrad]
	3039448586176 -> 3039448585360
	3039447811072 [label="backbone.features.6.conv.7.weight
 (32)" fillcolor=lightblue]
	3039447811072 -> 3039448586176
	3039448586176 [label=AccumulateGrad]
	3039448585456 -> 3039448585360
	3039447811152 [label="backbone.features.6.conv.7.bias
 (32)" fillcolor=lightblue]
	3039447811152 -> 3039448585456
	3039448585456 [label=AccumulateGrad]
	3039448585216 -> 3039448585072
	3039447811552 [label="backbone.features.7.conv.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	3039447811552 -> 3039448585216
	3039448585216 [label=AccumulateGrad]
	3039448585024 -> 3039448584976
	3039447811632 [label="backbone.features.7.conv.1.weight
 (192)" fillcolor=lightblue]
	3039447811632 -> 3039448585024
	3039448585024 [label=AccumulateGrad]
	3039448584880 -> 3039448584976
	3039447811712 [label="backbone.features.7.conv.1.bias
 (192)" fillcolor=lightblue]
	3039447811712 -> 3039448584880
	3039448584880 [label=AccumulateGrad]
	3039448584784 -> 3039448584640
	3039447812112 [label="backbone.features.7.conv.3.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	3039447812112 -> 3039448584784
	3039448584784 [label=AccumulateGrad]
	3039448584592 -> 3039448584544
	3039447812192 [label="backbone.features.7.conv.4.weight
 (192)" fillcolor=lightblue]
	3039447812192 -> 3039448584592
	3039448584592 [label=AccumulateGrad]
	3039448584448 -> 3039448584544
	3039447812272 [label="backbone.features.7.conv.4.bias
 (192)" fillcolor=lightblue]
	3039447812272 -> 3039448584448
	3039448584448 [label=AccumulateGrad]
	3039448584352 -> 3039448575952
	3039447812672 [label="backbone.features.7.conv.6.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	3039447812672 -> 3039448584352
	3039448584352 [label=AccumulateGrad]
	3039448575904 -> 3039448575808
	3039447812752 [label="backbone.features.7.conv.7.weight
 (64)" fillcolor=lightblue]
	3039447812752 -> 3039448575904
	3039448575904 [label=AccumulateGrad]
	3039448575856 -> 3039448575808
	3039447812832 [label="backbone.features.7.conv.7.bias
 (64)" fillcolor=lightblue]
	3039447812832 -> 3039448575856
	3039448575856 [label=AccumulateGrad]
	3039448575760 -> 3039448575664
	3039448575760 [label=CudnnBatchNormBackward0]
	3039448584304 -> 3039448575760
	3039448584304 [label=CudnnConvolutionBackward0]
	3039448584928 -> 3039448584304
	3039448584928 [label=HardtanhBackward0]
	3039448585312 -> 3039448584928
	3039448585312 [label=CudnnBatchNormBackward0]
	3039448598800 -> 3039448585312
	3039448598800 [label=ConvDepthwise2DBackward0]
	3039448599040 -> 3039448598800
	3039448599040 [label=HardtanhBackward0]
	3039448599280 -> 3039448599040
	3039448599280 [label=CudnnBatchNormBackward0]
	3039448599568 -> 3039448599280
	3039448599568 [label=CudnnConvolutionBackward0]
	3039448575808 -> 3039448599568
	3039448599760 -> 3039448599568
	3039447813232 [label="backbone.features.8.conv.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	3039447813232 -> 3039448599760
	3039448599760 [label=AccumulateGrad]
	3039448599520 -> 3039448599280
	3039447813312 [label="backbone.features.8.conv.1.weight
 (384)" fillcolor=lightblue]
	3039447813312 -> 3039448599520
	3039448599520 [label=AccumulateGrad]
	3039448599472 -> 3039448599280
	3039447813392 [label="backbone.features.8.conv.1.bias
 (384)" fillcolor=lightblue]
	3039447813392 -> 3039448599472
	3039448599472 [label=AccumulateGrad]
	3039448599232 -> 3039448598800
	3039447813792 [label="backbone.features.8.conv.3.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	3039447813792 -> 3039448599232
	3039448599232 [label=AccumulateGrad]
	3039448598848 -> 3039448585312
	3039447813872 [label="backbone.features.8.conv.4.weight
 (384)" fillcolor=lightblue]
	3039447813872 -> 3039448598848
	3039448598848 [label=AccumulateGrad]
	3039448596736 -> 3039448585312
	3039447813952 [label="backbone.features.8.conv.4.bias
 (384)" fillcolor=lightblue]
	3039447813952 -> 3039448596736
	3039448596736 [label=AccumulateGrad]
	3039448585120 -> 3039448584304
	3039447900464 [label="backbone.features.8.conv.6.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	3039447900464 -> 3039448585120
	3039448585120 [label=AccumulateGrad]
	3039448584496 -> 3039448575760
	3039447900544 [label="backbone.features.8.conv.7.weight
 (64)" fillcolor=lightblue]
	3039447900544 -> 3039448584496
	3039448584496 [label=AccumulateGrad]
	3039448584256 -> 3039448575760
	3039447900624 [label="backbone.features.8.conv.7.bias
 (64)" fillcolor=lightblue]
	3039447900624 -> 3039448584256
	3039448584256 [label=AccumulateGrad]
	3039448575616 -> 3039448575520
	3039448575616 [label=CudnnBatchNormBackward0]
	3039448575712 -> 3039448575616
	3039448575712 [label=CudnnConvolutionBackward0]
	3039448599712 -> 3039448575712
	3039448599712 [label=HardtanhBackward0]
	3039448599856 -> 3039448599712
	3039448599856 [label=CudnnBatchNormBackward0]
	3039448599664 -> 3039448599856
	3039448599664 [label=ConvDepthwise2DBackward0]
	3039448600048 -> 3039448599664
	3039448600048 [label=HardtanhBackward0]
	3039448600192 -> 3039448600048
	3039448600192 [label=CudnnBatchNormBackward0]
	3039448600288 -> 3039448600192
	3039448600288 [label=CudnnConvolutionBackward0]
	3039448575664 -> 3039448600288
	3039448600480 -> 3039448600288
	3039447901024 [label="backbone.features.9.conv.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	3039447901024 -> 3039448600480
	3039448600480 [label=AccumulateGrad]
	3039448600240 -> 3039448600192
	3039447901104 [label="backbone.features.9.conv.1.weight
 (384)" fillcolor=lightblue]
	3039447901104 -> 3039448600240
	3039448600240 [label=AccumulateGrad]
	3039448600096 -> 3039448600192
	3039447901184 [label="backbone.features.9.conv.1.bias
 (384)" fillcolor=lightblue]
	3039447901184 -> 3039448600096
	3039448600096 [label=AccumulateGrad]
	3039448600000 -> 3039448599664
	3039447901584 [label="backbone.features.9.conv.3.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	3039447901584 -> 3039448600000
	3039448600000 [label=AccumulateGrad]
	3039448599808 -> 3039448599856
	3039447901664 [label="backbone.features.9.conv.4.weight
 (384)" fillcolor=lightblue]
	3039447901664 -> 3039448599808
	3039448599808 [label=AccumulateGrad]
	3039448599616 -> 3039448599856
	3039447901744 [label="backbone.features.9.conv.4.bias
 (384)" fillcolor=lightblue]
	3039447901744 -> 3039448599616
	3039448599616 [label=AccumulateGrad]
	3039448598416 -> 3039448575712
	3039447902144 [label="backbone.features.9.conv.6.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	3039447902144 -> 3039448598416
	3039448598416 [label=AccumulateGrad]
	3039448585168 -> 3039448575616
	3039447902224 [label="backbone.features.9.conv.7.weight
 (64)" fillcolor=lightblue]
	3039447902224 -> 3039448585168
	3039448585168 [label=AccumulateGrad]
	3039448584736 -> 3039448575616
	3039447902304 [label="backbone.features.9.conv.7.bias
 (64)" fillcolor=lightblue]
	3039447902304 -> 3039448584736
	3039448584736 [label=AccumulateGrad]
	3039448575472 -> 3039448575376
	3039448575472 [label=CudnnBatchNormBackward0]
	3039448587376 -> 3039448575472
	3039448587376 [label=CudnnConvolutionBackward0]
	3039448600432 -> 3039448587376
	3039448600432 [label=HardtanhBackward0]
	3039448600528 -> 3039448600432
	3039448600528 [label=CudnnBatchNormBackward0]
	3039448600384 -> 3039448600528
	3039448600384 [label=ConvDepthwise2DBackward0]
	3039448654080 -> 3039448600384
	3039448654080 [label=HardtanhBackward0]
	3039448654224 -> 3039448654080
	3039448654224 [label=CudnnBatchNormBackward0]
	3039448654320 -> 3039448654224
	3039448654320 [label=CudnnConvolutionBackward0]
	3039448575520 -> 3039448654320
	3039448654512 -> 3039448654320
	3039447902624 [label="backbone.features.10.conv.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	3039447902624 -> 3039448654512
	3039448654512 [label=AccumulateGrad]
	3039448654272 -> 3039448654224
	3039447902704 [label="backbone.features.10.conv.1.weight
 (384)" fillcolor=lightblue]
	3039447902704 -> 3039448654272
	3039448654272 [label=AccumulateGrad]
	3039448654128 -> 3039448654224
	3039447902784 [label="backbone.features.10.conv.1.bias
 (384)" fillcolor=lightblue]
	3039447902784 -> 3039448654128
	3039448654128 [label=AccumulateGrad]
	3039448654032 -> 3039448600384
	3039447903184 [label="backbone.features.10.conv.3.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	3039447903184 -> 3039448654032
	3039448654032 [label=AccumulateGrad]
	3039448600336 -> 3039448600528
	3039447903264 [label="backbone.features.10.conv.4.weight
 (384)" fillcolor=lightblue]
	3039447903264 -> 3039448600336
	3039448600336 [label=AccumulateGrad]
	3039448653888 -> 3039448600528
	3039447903344 [label="backbone.features.10.conv.4.bias
 (384)" fillcolor=lightblue]
	3039447903344 -> 3039448653888
	3039448653888 [label=AccumulateGrad]
	3039448599424 -> 3039448587376
	3039447903744 [label="backbone.features.10.conv.6.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	3039447903744 -> 3039448599424
	3039448599424 [label=AccumulateGrad]
	3039448575568 -> 3039448575472
	3039447903824 [label="backbone.features.10.conv.7.weight
 (64)" fillcolor=lightblue]
	3039447903824 -> 3039448575568
	3039448575568 [label=AccumulateGrad]
	3039448599328 -> 3039448575472
	3039447903904 [label="backbone.features.10.conv.7.bias
 (64)" fillcolor=lightblue]
	3039447903904 -> 3039448599328
	3039448599328 [label=AccumulateGrad]
	3039448575328 -> 3039448575184
	3039447994512 [label="backbone.features.11.conv.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	3039447994512 -> 3039448575328
	3039448575328 [label=AccumulateGrad]
	3039448575136 -> 3039448575088
	3039447994592 [label="backbone.features.11.conv.1.weight
 (384)" fillcolor=lightblue]
	3039447994592 -> 3039448575136
	3039448575136 [label=AccumulateGrad]
	3039448574992 -> 3039448575088
	3039447994672 [label="backbone.features.11.conv.1.bias
 (384)" fillcolor=lightblue]
	3039447994672 -> 3039448574992
	3039448574992 [label=AccumulateGrad]
	3039448574896 -> 3039448574752
	3039447995072 [label="backbone.features.11.conv.3.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	3039447995072 -> 3039448574896
	3039448574896 [label=AccumulateGrad]
	3039448574704 -> 3039448574656
	3039447995152 [label="backbone.features.11.conv.4.weight
 (384)" fillcolor=lightblue]
	3039447995152 -> 3039448574704
	3039448574704 [label=AccumulateGrad]
	3039448574560 -> 3039448574656
	3039447995232 [label="backbone.features.11.conv.4.bias
 (384)" fillcolor=lightblue]
	3039447995232 -> 3039448574560
	3039448574560 [label=AccumulateGrad]
	3039448574464 -> 3039448574320
	3039447995632 [label="backbone.features.11.conv.6.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	3039447995632 -> 3039448574464
	3039448574464 [label=AccumulateGrad]
	3039448574272 -> 3039448574176
	3039447995712 [label="backbone.features.11.conv.7.weight
 (96)" fillcolor=lightblue]
	3039447995712 -> 3039448574272
	3039448574272 [label=AccumulateGrad]
	3039448574224 -> 3039448574176
	3039447995792 [label="backbone.features.11.conv.7.bias
 (96)" fillcolor=lightblue]
	3039447995792 -> 3039448574224
	3039448574224 [label=AccumulateGrad]
	3039448574128 -> 3039448574032
	3039448574128 [label=CudnnBatchNormBackward0]
	3039448574848 -> 3039448574128
	3039448574848 [label=CudnnConvolutionBackward0]
	3039448575232 -> 3039448574848
	3039448575232 [label=HardtanhBackward0]
	3039448575424 -> 3039448575232
	3039448575424 [label=CudnnBatchNormBackward0]
	3039448600144 -> 3039448575424
	3039448600144 [label=ConvDepthwise2DBackward0]
	3039448654368 -> 3039448600144
	3039448654368 [label=HardtanhBackward0]
	3039448654560 -> 3039448654368
	3039448654560 [label=CudnnBatchNormBackward0]
	3039448654656 -> 3039448654560
	3039448654656 [label=CudnnConvolutionBackward0]
	3039448574176 -> 3039448654656
	3039448654848 -> 3039448654656
	3039447996192 [label="backbone.features.12.conv.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	3039447996192 -> 3039448654848
	3039448654848 [label=AccumulateGrad]
	3039448654416 -> 3039448654560
	3039447996272 [label="backbone.features.12.conv.1.weight
 (576)" fillcolor=lightblue]
	3039447996272 -> 3039448654416
	3039448654416 [label=AccumulateGrad]
	3039448654176 -> 3039448654560
	3039447996352 [label="backbone.features.12.conv.1.bias
 (576)" fillcolor=lightblue]
	3039447996352 -> 3039448654176
	3039448654176 [label=AccumulateGrad]
	3039448654464 -> 3039448600144
	3039447996752 [label="backbone.features.12.conv.3.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	3039447996752 -> 3039448654464
	3039448654464 [label=AccumulateGrad]
	3039448599952 -> 3039448575424
	3039447996832 [label="backbone.features.12.conv.4.weight
 (576)" fillcolor=lightblue]
	3039447996832 -> 3039448599952
	3039448599952 [label=AccumulateGrad]
	3039448599904 -> 3039448575424
	3039447996912 [label="backbone.features.12.conv.4.bias
 (576)" fillcolor=lightblue]
	3039447996912 -> 3039448599904
	3039448599904 [label=AccumulateGrad]
	3039448575280 -> 3039448574848
	3039447997312 [label="backbone.features.12.conv.6.weight
 (96, 576, 1, 1)" fillcolor=lightblue]
	3039447997312 -> 3039448575280
	3039448575280 [label=AccumulateGrad]
	3039448574416 -> 3039448574128
	3039447997392 [label="backbone.features.12.conv.7.weight
 (96)" fillcolor=lightblue]
	3039447997392 -> 3039448574416
	3039448574416 [label=AccumulateGrad]
	3039448574368 -> 3039448574128
	3039447997472 [label="backbone.features.12.conv.7.bias
 (96)" fillcolor=lightblue]
	3039447997472 -> 3039448574368
	3039448574368 [label=AccumulateGrad]
	3039448573984 -> 3039448573888
	3039448573984 [label=CudnnBatchNormBackward0]
	3039448574608 -> 3039448573984
	3039448574608 [label=CudnnConvolutionBackward0]
	3039448654800 -> 3039448574608
	3039448654800 [label=HardtanhBackward0]
	3039448654944 -> 3039448654800
	3039448654944 [label=CudnnBatchNormBackward0]
	3039448654752 -> 3039448654944
	3039448654752 [label=ConvDepthwise2DBackward0]
	3039448655136 -> 3039448654752
	3039448655136 [label=HardtanhBackward0]
	3039448655280 -> 3039448655136
	3039448655280 [label=CudnnBatchNormBackward0]
	3039448655376 -> 3039448655280
	3039448655376 [label=CudnnConvolutionBackward0]
	3039448574032 -> 3039448655376
	3039448655568 -> 3039448655376
	3039447997872 [label="backbone.features.13.conv.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	3039447997872 -> 3039448655568
	3039448655568 [label=AccumulateGrad]
	3039448655328 -> 3039448655280
	3039447997952 [label="backbone.features.13.conv.1.weight
 (576)" fillcolor=lightblue]
	3039447997952 -> 3039448655328
	3039448655328 [label=AccumulateGrad]
	3039448655184 -> 3039448655280
	3039447998032 [label="backbone.features.13.conv.1.bias
 (576)" fillcolor=lightblue]
	3039447998032 -> 3039448655184
	3039448655184 [label=AccumulateGrad]
	3039448655088 -> 3039448654752
	3039448068160 [label="backbone.features.13.conv.3.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	3039448068160 -> 3039448655088
	3039448655088 [label=AccumulateGrad]
	3039448654896 -> 3039448654944
	3039448068240 [label="backbone.features.13.conv.4.weight
 (576)" fillcolor=lightblue]
	3039448068240 -> 3039448654896
	3039448654896 [label=AccumulateGrad]
	3039448654704 -> 3039448654944
	3039448068320 [label="backbone.features.13.conv.4.bias
 (576)" fillcolor=lightblue]
	3039448068320 -> 3039448654704
	3039448654704 [label=AccumulateGrad]
	3039448653984 -> 3039448574608
	3039448068720 [label="backbone.features.13.conv.6.weight
 (96, 576, 1, 1)" fillcolor=lightblue]
	3039448068720 -> 3039448653984
	3039448653984 [label=AccumulateGrad]
	3039448574800 -> 3039448573984
	3039448068800 [label="backbone.features.13.conv.7.weight
 (96)" fillcolor=lightblue]
	3039448068800 -> 3039448574800
	3039448574800 [label=AccumulateGrad]
	3039448574080 -> 3039448573984
	3039448068880 [label="backbone.features.13.conv.7.bias
 (96)" fillcolor=lightblue]
	3039448068880 -> 3039448574080
	3039448574080 [label=AccumulateGrad]
	3039448573840 -> 3039448573696
	3039448069280 [label="backbone.features.14.conv.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	3039448069280 -> 3039448573840
	3039448573840 [label=AccumulateGrad]
	3039448573648 -> 3039448573600
	3039448069360 [label="backbone.features.14.conv.1.weight
 (576)" fillcolor=lightblue]
	3039448069360 -> 3039448573648
	3039448573648 [label=AccumulateGrad]
	3039448573504 -> 3039448573600
	3039448069440 [label="backbone.features.14.conv.1.bias
 (576)" fillcolor=lightblue]
	3039448069440 -> 3039448573504
	3039448573504 [label=AccumulateGrad]
	3039448573408 -> 3039448573264
	3039448069840 [label="backbone.features.14.conv.3.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	3039448069840 -> 3039448573408
	3039448573408 [label=AccumulateGrad]
	3039448573216 -> 3039448573168
	3039448069920 [label="backbone.features.14.conv.4.weight
 (576)" fillcolor=lightblue]
	3039448069920 -> 3039448573216
	3039448573216 [label=AccumulateGrad]
	3039448573072 -> 3039448573168
	3039448070000 [label="backbone.features.14.conv.4.bias
 (576)" fillcolor=lightblue]
	3039448070000 -> 3039448573072
	3039448573072 [label=AccumulateGrad]
	3039448572976 -> 3039448572832
	3039448070400 [label="backbone.features.14.conv.6.weight
 (160, 576, 1, 1)" fillcolor=lightblue]
	3039448070400 -> 3039448572976
	3039448572976 [label=AccumulateGrad]
	3039448572784 -> 3039448572688
	3039448070480 [label="backbone.features.14.conv.7.weight
 (160)" fillcolor=lightblue]
	3039448070480 -> 3039448572784
	3039448572784 [label=AccumulateGrad]
	3039448572736 -> 3039448572688
	3039448070560 [label="backbone.features.14.conv.7.bias
 (160)" fillcolor=lightblue]
	3039448070560 -> 3039448572736
	3039448572736 [label=AccumulateGrad]
	3039448572640 -> 3039448572544
	3039448572640 [label=CudnnBatchNormBackward0]
	3039448573360 -> 3039448572640
	3039448573360 [label=CudnnConvolutionBackward0]
	3039448573744 -> 3039448573360
	3039448573744 [label=HardtanhBackward0]
	3039448573936 -> 3039448573744
	3039448573936 [label=CudnnBatchNormBackward0]
	3039448573552 -> 3039448573936
	3039448573552 [label=ConvDepthwise2DBackward0]
	3039448655424 -> 3039448573552
	3039448655424 [label=HardtanhBackward0]
	3039448655616 -> 3039448655424
	3039448655616 [label=CudnnBatchNormBackward0]
	3039448655712 -> 3039448655616
	3039448655712 [label=CudnnConvolutionBackward0]
	3039448572688 -> 3039448655712
	3039448655904 -> 3039448655712
	3039448070960 [label="backbone.features.15.conv.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	3039448070960 -> 3039448655904
	3039448655904 [label=AccumulateGrad]
	3039448655472 -> 3039448655616
	3039448071040 [label="backbone.features.15.conv.1.weight
 (960)" fillcolor=lightblue]
	3039448071040 -> 3039448655472
	3039448655472 [label=AccumulateGrad]
	3039448655232 -> 3039448655616
	3039448071120 [label="backbone.features.15.conv.1.bias
 (960)" fillcolor=lightblue]
	3039448071120 -> 3039448655232
	3039448655232 [label=AccumulateGrad]
	3039448655520 -> 3039448573552
	3039448071520 [label="backbone.features.15.conv.3.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	3039448071520 -> 3039448655520
	3039448655520 [label=AccumulateGrad]
	3039448655040 -> 3039448573936
	3039448071600 [label="backbone.features.15.conv.4.weight
 (960)" fillcolor=lightblue]
	3039448071600 -> 3039448655040
	3039448655040 [label=AccumulateGrad]
	3039448653936 -> 3039448573936
	3039448071680 [label="backbone.features.15.conv.4.bias
 (960)" fillcolor=lightblue]
	3039448071680 -> 3039448653936
	3039448653936 [label=AccumulateGrad]
	3039448573792 -> 3039448573360
	3039448072080 [label="backbone.features.15.conv.6.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	3039448072080 -> 3039448573792
	3039448573792 [label=AccumulateGrad]
	3039448572928 -> 3039448572640
	3039448158272 [label="backbone.features.15.conv.7.weight
 (160)" fillcolor=lightblue]
	3039448158272 -> 3039448572928
	3039448572928 [label=AccumulateGrad]
	3039448572880 -> 3039448572640
	3039448158352 [label="backbone.features.15.conv.7.bias
 (160)" fillcolor=lightblue]
	3039448158352 -> 3039448572880
	3039448572880 [label=AccumulateGrad]
	3039448572496 -> 3039448572400
	3039448572496 [label=CudnnBatchNormBackward0]
	3039448573120 -> 3039448572496
	3039448573120 [label=CudnnConvolutionBackward0]
	3039448655856 -> 3039448573120
	3039448655856 [label=HardtanhBackward0]
	3039448656000 -> 3039448655856
	3039448656000 [label=CudnnBatchNormBackward0]
	3039448655808 -> 3039448656000
	3039448655808 [label=ConvDepthwise2DBackward0]
	3039448656192 -> 3039448655808
	3039448656192 [label=HardtanhBackward0]
	3039448656336 -> 3039448656192
	3039448656336 [label=CudnnBatchNormBackward0]
	3039448656432 -> 3039448656336
	3039448656432 [label=CudnnConvolutionBackward0]
	3039448572544 -> 3039448656432
	3039448656624 -> 3039448656432
	3039448158752 [label="backbone.features.16.conv.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	3039448158752 -> 3039448656624
	3039448656624 [label=AccumulateGrad]
	3039448656384 -> 3039448656336
	3039448158832 [label="backbone.features.16.conv.1.weight
 (960)" fillcolor=lightblue]
	3039448158832 -> 3039448656384
	3039448656384 [label=AccumulateGrad]
	3039448656240 -> 3039448656336
	3039448158912 [label="backbone.features.16.conv.1.bias
 (960)" fillcolor=lightblue]
	3039448158912 -> 3039448656240
	3039448656240 [label=AccumulateGrad]
	3039448656144 -> 3039448655808
	3039448159312 [label="backbone.features.16.conv.3.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	3039448159312 -> 3039448656144
	3039448656144 [label=AccumulateGrad]
	3039448655952 -> 3039448656000
	3039448159392 [label="backbone.features.16.conv.4.weight
 (960)" fillcolor=lightblue]
	3039448159392 -> 3039448655952
	3039448655952 [label=AccumulateGrad]
	3039448655760 -> 3039448656000
	3039448159472 [label="backbone.features.16.conv.4.bias
 (960)" fillcolor=lightblue]
	3039448159472 -> 3039448655760
	3039448655760 [label=AccumulateGrad]
	3039448654992 -> 3039448573120
	3039448159872 [label="backbone.features.16.conv.6.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	3039448159872 -> 3039448654992
	3039448654992 [label=AccumulateGrad]
	3039448573312 -> 3039448572496
	3039448159952 [label="backbone.features.16.conv.7.weight
 (160)" fillcolor=lightblue]
	3039448159952 -> 3039448573312
	3039448573312 [label=AccumulateGrad]
	3039448572592 -> 3039448572496
	3039448160032 [label="backbone.features.16.conv.7.bias
 (160)" fillcolor=lightblue]
	3039448160032 -> 3039448572592
	3039448572592 [label=AccumulateGrad]
	3039448572352 -> 3039448572208
	3039448160432 [label="backbone.features.17.conv.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	3039448160432 -> 3039448572352
	3039448572352 [label=AccumulateGrad]
	3039448572160 -> 3039448572112
	3039448160512 [label="backbone.features.17.conv.1.weight
 (960)" fillcolor=lightblue]
	3039448160512 -> 3039448572160
	3039448572160 [label=AccumulateGrad]
	3039448572016 -> 3039448572112
	3039448160592 [label="backbone.features.17.conv.1.bias
 (960)" fillcolor=lightblue]
	3039448160592 -> 3039448572016
	3039448572016 [label=AccumulateGrad]
	3039448395680 -> 3039448395584
	3039448160992 [label="backbone.features.17.conv.3.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	3039448160992 -> 3039448395680
	3039448395680 [label=AccumulateGrad]
	3039448395536 -> 3039448395488
	3039448161072 [label="backbone.features.17.conv.4.weight
 (960)" fillcolor=lightblue]
	3039448161072 -> 3039448395536
	3039448395536 [label=AccumulateGrad]
	3039448395392 -> 3039448395488
	3039448161152 [label="backbone.features.17.conv.4.bias
 (960)" fillcolor=lightblue]
	3039448161152 -> 3039448395392
	3039448395392 [label=AccumulateGrad]
	3039448395296 -> 3039448395152
	3039448161552 [label="backbone.features.17.conv.6.weight
 (320, 960, 1, 1)" fillcolor=lightblue]
	3039448161552 -> 3039448395296
	3039448395296 [label=AccumulateGrad]
	3039448395104 -> 3039448394864
	3039448161632 [label="backbone.features.17.conv.7.weight
 (320)" fillcolor=lightblue]
	3039448161632 -> 3039448395104
	3039448395104 [label=AccumulateGrad]
	3039448395056 -> 3039448394864
	3039448161712 [label="backbone.features.17.conv.7.bias
 (320)" fillcolor=lightblue]
	3039448161712 -> 3039448395056
	3039448395056 [label=AccumulateGrad]
	3039448394816 -> 3039448394720
	3039448394816 [label=UpsampleBilinear2DBackward1]
	3039448395632 -> 3039448394816
	3039448395632 [label=MulBackward0]
	3039448395440 -> 3039448395632
	3039448395440 [label=MulBackward0]
	3039448572064 -> 3039448395440
	3039448572064 [label=ReluBackward0]
	3039448572448 -> 3039448572064
	3039448572448 [label=CudnnBatchNormBackward0]
	3039448656048 -> 3039448572448
	3039448656048 [label=CudnnConvolutionBackward0]
	3039448656288 -> 3039448656048
	3039448656288 [label=MeanBackward1]
	3039448394864 -> 3039448656288
	3039448656480 -> 3039448656048
	3039448162112 [label="master_branch.0.stages.0.1.weight
 (80, 320, 1, 1)" fillcolor=lightblue]
	3039448162112 -> 3039448656480
	3039448656480 [label=AccumulateGrad]
	3039448656096 -> 3039448572448
	3039448236256 [label="master_branch.0.stages.0.2.weight
 (80)" fillcolor=lightblue]
	3039448236256 -> 3039448656096
	3039448656096 [label=AccumulateGrad]
	3039448654608 -> 3039448572448
	3039448236576 [label="master_branch.0.stages.0.2.bias
 (80)" fillcolor=lightblue]
	3039448236576 -> 3039448654608
	3039448654608 [label=AccumulateGrad]
	3039448572256 -> 3039448395440
	3039448572256 [label=SigmoidBackward0]
	3039448575040 -> 3039448572256
	3039448575040 [label=AddBackward0]
	3039448656672 -> 3039448575040
	3039448656672 [label=CudnnConvolutionBackward0]
	3039448656816 -> 3039448656672
	3039448656816 [label=ReluBackward0]
	3039448656960 -> 3039448656816
	3039448656960 [label=CudnnConvolutionBackward0]
	3039448657056 -> 3039448656960
	3039448657056 [label=MeanBackward1]
	3039448572064 -> 3039448657056
	3039448657008 -> 3039448656960
	3039448236416 [label="master_branch.0.stages.0.4.channelattention.fc1.weight
 (10, 80, 1, 1)" fillcolor=lightblue]
	3039448236416 -> 3039448657008
	3039448657008 [label=AccumulateGrad]
	3039448656768 -> 3039448656672
	3039448236896 [label="master_branch.0.stages.0.4.channelattention.fc2.weight
 (80, 10, 1, 1)" fillcolor=lightblue]
	3039448236896 -> 3039448656768
	3039448656768 [label=AccumulateGrad]
	3039448656720 -> 3039448575040
	3039448656720 [label=CudnnConvolutionBackward0]
	3039448656864 -> 3039448656720
	3039448656864 [label=ReluBackward0]
	3039448657152 -> 3039448656864
	3039448657152 [label=CudnnConvolutionBackward0]
	3039448657248 -> 3039448657152
	3039448657248 [label=AdaptiveMaxPool2DBackward0]
	3039448572064 -> 3039448657248
	3039448657008 -> 3039448657152
	3039448656768 -> 3039448656720
	3039448395200 -> 3039448395632
	3039448395200 [label=SigmoidBackward0]
	3039448572304 -> 3039448395200
	3039448572304 [label=CudnnConvolutionBackward0]
	3039448656912 -> 3039448572304
	3039448656912 [label=CatBackward0]
	3039448657296 -> 3039448656912
	3039448657296 [label=MeanBackward1]
	3039448395440 -> 3039448657296
	3039448657344 -> 3039448656912
	3039448657344 [label=MaxBackward0]
	3039448395440 -> 3039448657344
	3039448657104 -> 3039448572304
	3039448236816 [label="master_branch.0.stages.0.4.spatialattention.conv1.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	3039448236816 -> 3039448657104
	3039448657104 [label=AccumulateGrad]
	3039448394768 -> 3039448394720
	3039448394768 [label=UpsampleBilinear2DBackward1]
	3039448571968 -> 3039448394768
	3039448571968 [label=MulBackward0]
	3039448656528 -> 3039448571968
	3039448656528 [label=MulBackward0]
	3039448657488 -> 3039448656528
	3039448657488 [label=ReluBackward0]
	3039448657632 -> 3039448657488
	3039448657632 [label=CudnnBatchNormBackward0]
	3039448657728 -> 3039448657632
	3039448657728 [label=CudnnConvolutionBackward0]
	3039448657872 -> 3039448657728
	3039448657872 [label=AdaptiveAvgPool2DBackward0]
	3039448394864 -> 3039448657872
	3039448657824 -> 3039448657728
	3039448237056 [label="master_branch.0.stages.1.1.weight
 (80, 320, 1, 1)" fillcolor=lightblue]
	3039448237056 -> 3039448657824
	3039448657824 [label=AccumulateGrad]
	3039448657680 -> 3039448657632
	3039448237216 [label="master_branch.0.stages.1.2.weight
 (80)" fillcolor=lightblue]
	3039448237216 -> 3039448657680
	3039448657680 [label=AccumulateGrad]
	3039448657536 -> 3039448657632
	3039448237296 [label="master_branch.0.stages.1.2.bias
 (80)" fillcolor=lightblue]
	3039448237296 -> 3039448657536
	3039448657536 [label=AccumulateGrad]
	3039448657440 -> 3039448656528
	3039448657440 [label=SigmoidBackward0]
	3039448657776 -> 3039448657440
	3039448657776 [label=AddBackward0]
	3039448703136 -> 3039448657776
	3039448703136 [label=CudnnConvolutionBackward0]
	3039448703280 -> 3039448703136
	3039448703280 [label=ReluBackward0]
	3039448703424 -> 3039448703280
	3039448703424 [label=CudnnConvolutionBackward0]
	3039448703520 -> 3039448703424
	3039448703520 [label=MeanBackward1]
	3039448657488 -> 3039448703520
	3039448703472 -> 3039448703424
	3039448237696 [label="master_branch.0.stages.1.4.channelattention.fc1.weight
 (10, 80, 1, 1)" fillcolor=lightblue]
	3039448237696 -> 3039448703472
	3039448703472 [label=AccumulateGrad]
	3039448703232 -> 3039448703136
	3039448237856 [label="master_branch.0.stages.1.4.channelattention.fc2.weight
 (80, 10, 1, 1)" fillcolor=lightblue]
	3039448237856 -> 3039448703232
	3039448703232 [label=AccumulateGrad]
	3039448703088 -> 3039448657776
	3039448703088 [label=CudnnConvolutionBackward0]
	3039448703328 -> 3039448703088
	3039448703328 [label=ReluBackward0]
	3039448703616 -> 3039448703328
	3039448703616 [label=CudnnConvolutionBackward0]
	3039448703712 -> 3039448703616
	3039448703712 [label=AdaptiveMaxPool2DBackward0]
	3039448657488 -> 3039448703712
	3039448703472 -> 3039448703616
	3039448703232 -> 3039448703088
	3039448657392 -> 3039448571968
	3039448657392 [label=SigmoidBackward0]
	3039448657584 -> 3039448657392
	3039448657584 [label=CudnnConvolutionBackward0]
	3039448703376 -> 3039448657584
	3039448703376 [label=CatBackward0]
	3039448703760 -> 3039448703376
	3039448703760 [label=MeanBackward1]
	3039448656528 -> 3039448703760
	3039448703808 -> 3039448703376
	3039448703808 [label=MaxBackward0]
	3039448656528 -> 3039448703808
	3039448703568 -> 3039448657584
	3039448238016 [label="master_branch.0.stages.1.4.spatialattention.conv1.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	3039448238016 -> 3039448703568
	3039448703568 [label=AccumulateGrad]
	3039448394912 -> 3039448394720
	3039448394912 [label=UpsampleBilinear2DBackward1]
	3039448657200 -> 3039448394912
	3039448657200 [label=MulBackward0]
	3039448395248 -> 3039448657200
	3039448395248 [label=MulBackward0]
	3039448703904 -> 3039448395248
	3039448703904 [label=ReluBackward0]
	3039448704048 -> 3039448703904
	3039448704048 [label=CudnnBatchNormBackward0]
	3039448704144 -> 3039448704048
	3039448704144 [label=CudnnConvolutionBackward0]
	3039448704336 -> 3039448704144
	3039448704336 [label=AdaptiveAvgPool2DBackward0]
	3039448394864 -> 3039448704336
	3039448704288 -> 3039448704144
	3039448238176 [label="master_branch.0.stages.2.1.weight
 (80, 320, 1, 1)" fillcolor=lightblue]
	3039448238176 -> 3039448704288
	3039448704288 [label=AccumulateGrad]
	3039448704096 -> 3039448704048
	3039448238256 [label="master_branch.0.stages.2.2.weight
 (80)" fillcolor=lightblue]
	3039448238256 -> 3039448704096
	3039448704096 [label=AccumulateGrad]
	3039448703952 -> 3039448704048
	3039448238336 [label="master_branch.0.stages.2.2.bias
 (80)" fillcolor=lightblue]
	3039448238336 -> 3039448703952
	3039448703952 [label=AccumulateGrad]
	3039448703664 -> 3039448395248
	3039448703664 [label=SigmoidBackward0]
	3039448704240 -> 3039448703664
	3039448704240 [label=AddBackward0]
	3039448704432 -> 3039448704240
	3039448704432 [label=CudnnConvolutionBackward0]
	3039448704576 -> 3039448704432
	3039448704576 [label=ReluBackward0]
	3039448704720 -> 3039448704576
	3039448704720 [label=CudnnConvolutionBackward0]
	3039448704816 -> 3039448704720
	3039448704816 [label=MeanBackward1]
	3039448703904 -> 3039448704816
	3039448704768 -> 3039448704720
	3039448238736 [label="master_branch.0.stages.2.4.channelattention.fc1.weight
 (10, 80, 1, 1)" fillcolor=lightblue]
	3039448238736 -> 3039448704768
	3039448704768 [label=AccumulateGrad]
	3039448704528 -> 3039448704432
	3039448238896 [label="master_branch.0.stages.2.4.channelattention.fc2.weight
 (80, 10, 1, 1)" fillcolor=lightblue]
	3039448238896 -> 3039448704528
	3039448704528 [label=AccumulateGrad]
	3039448704384 -> 3039448704240
	3039448704384 [label=CudnnConvolutionBackward0]
	3039448704624 -> 3039448704384
	3039448704624 [label=ReluBackward0]
	3039448704912 -> 3039448704624
	3039448704912 [label=CudnnConvolutionBackward0]
	3039448705008 -> 3039448704912
	3039448705008 [label=AdaptiveMaxPool2DBackward0]
	3039448703904 -> 3039448705008
	3039448704768 -> 3039448704912
	3039448704528 -> 3039448704384
	3039448703856 -> 3039448657200
	3039448703856 [label=SigmoidBackward0]
	3039448704000 -> 3039448703856
	3039448704000 [label=CudnnConvolutionBackward0]
	3039448704672 -> 3039448704000
	3039448704672 [label=CatBackward0]
	3039448705056 -> 3039448704672
	3039448705056 [label=MeanBackward1]
	3039448395248 -> 3039448705056
	3039448705104 -> 3039448704672
	3039448705104 [label=MaxBackward0]
	3039448395248 -> 3039448705104
	3039448704864 -> 3039448704000
	3039448239056 [label="master_branch.0.stages.2.4.spatialattention.conv1.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	3039448239056 -> 3039448704864
	3039448704864 [label=AccumulateGrad]
	3039448394960 -> 3039448394720
	3039448394960 [label=UpsampleBilinear2DBackward1]
	3039448656576 -> 3039448394960
	3039448656576 [label=MulBackward0]
	3039448705152 -> 3039448656576
	3039448705152 [label=MulBackward0]
	3039448705200 -> 3039448705152
	3039448705200 [label=ReluBackward0]
	3039448705344 -> 3039448705200
	3039448705344 [label=CudnnBatchNormBackward0]
	3039448705440 -> 3039448705344
	3039448705440 [label=CudnnConvolutionBackward0]
	3039448705632 -> 3039448705440
	3039448705632 [label=AdaptiveAvgPool2DBackward0]
	3039448394864 -> 3039448705632
	3039448705584 -> 3039448705440
	3039448239216 [label="master_branch.0.stages.3.1.weight
 (80, 320, 1, 1)" fillcolor=lightblue]
	3039448239216 -> 3039448705584
	3039448705584 [label=AccumulateGrad]
	3039448705392 -> 3039448705344
	3039448239296 [label="master_branch.0.stages.3.2.weight
 (80)" fillcolor=lightblue]
	3039448239296 -> 3039448705392
	3039448705392 [label=AccumulateGrad]
	3039448705248 -> 3039448705344
	3039448239376 [label="master_branch.0.stages.3.2.bias
 (80)" fillcolor=lightblue]
	3039448239376 -> 3039448705248
	3039448705248 [label=AccumulateGrad]
	3039448704960 -> 3039448705152
	3039448704960 [label=SigmoidBackward0]
	3039448705536 -> 3039448704960
	3039448705536 [label=AddBackward0]
	3039448705728 -> 3039448705536
	3039448705728 [label=CudnnConvolutionBackward0]
	3039448705872 -> 3039448705728
	3039448705872 [label=ReluBackward0]
	3039448706016 -> 3039448705872
	3039448706016 [label=CudnnConvolutionBackward0]
	3039448706112 -> 3039448706016
	3039448706112 [label=MeanBackward1]
	3039448705200 -> 3039448706112
	3039448706064 -> 3039448706016
	3039448239776 [label="master_branch.0.stages.3.4.channelattention.fc1.weight
 (10, 80, 1, 1)" fillcolor=lightblue]
	3039448239776 -> 3039448706064
	3039448706064 [label=AccumulateGrad]
	3039448705824 -> 3039448705728
	3039448239936 [label="master_branch.0.stages.3.4.channelattention.fc2.weight
 (80, 10, 1, 1)" fillcolor=lightblue]
	3039448239936 -> 3039448705824
	3039448705824 [label=AccumulateGrad]
	3039448705680 -> 3039448705536
	3039448705680 [label=CudnnConvolutionBackward0]
	3039448705920 -> 3039448705680
	3039448705920 [label=ReluBackward0]
	3039448706208 -> 3039448705920
	3039448706208 [label=CudnnConvolutionBackward0]
	3039448706304 -> 3039448706208
	3039448706304 [label=AdaptiveMaxPool2DBackward0]
	3039448705200 -> 3039448706304
	3039448706064 -> 3039448706208
	3039448705824 -> 3039448705680
	3039448703184 -> 3039448656576
	3039448703184 [label=SigmoidBackward0]
	3039448705296 -> 3039448703184
	3039448705296 [label=CudnnConvolutionBackward0]
	3039448705968 -> 3039448705296
	3039448705968 [label=CatBackward0]
	3039448706352 -> 3039448705968
	3039448706352 [label=MeanBackward1]
	3039448705152 -> 3039448706352
	3039448706400 -> 3039448705968
	3039448706400 [label=MaxBackward0]
	3039448705152 -> 3039448706400
	3039448706160 -> 3039448705296
	3039448453184 [label="master_branch.0.stages.3.4.spatialattention.conv1.weight
 (1, 2, 7, 7)" fillcolor=lightblue]
	3039448453184 -> 3039448706160
	3039448706160 [label=AccumulateGrad]
	3039448394672 -> 3039448394528
	3039448453344 [label="master_branch.0.bottleneck.0.weight
 (80, 640, 3, 3)" fillcolor=lightblue]
	3039448453344 -> 3039448394672
	3039448394672 [label=AccumulateGrad]
	3039448394480 -> 3039448394432
	3039448453424 [label="master_branch.0.bottleneck.1.weight
 (80)" fillcolor=lightblue]
	3039448453424 -> 3039448394480
	3039448394480 [label=AccumulateGrad]
	3039448394240 -> 3039448394432
	3039448453504 [label="master_branch.0.bottleneck.1.bias
 (80)" fillcolor=lightblue]
	3039448453504 -> 3039448394240
	3039448394240 [label=AccumulateGrad]
	3039448394144 -> 3039448393904
	3039448453904 [label="master_branch.1.weight
 (3, 80, 1, 1)" fillcolor=lightblue]
	3039448453904 -> 3039448394144
	3039448394144 [label=AccumulateGrad]
	3039448393760 -> 3039448394096
	3039448393760 [label=ReshapeAliasBackward0]
	3039448394384 -> 3039448393760
	3039448453984 [label="master_branch.1.bias
 (3)" fillcolor=lightblue]
	3039448453984 -> 3039448394384
	3039448394384 [label=AccumulateGrad]
	3039448394000 -> 3039447486112
}
